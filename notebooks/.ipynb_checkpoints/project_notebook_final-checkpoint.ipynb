{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17660bd9",
   "metadata": {},
   "source": [
    "# Flatiron Phase 4 Project\n",
    "\n",
    "## Aaron Galbraith\n",
    "\n",
    "### Submitted: \n",
    "\n",
    "# Business Understanding\n",
    "\n",
    "\n",
    "\n",
    "# Data Understanding\n",
    "\n",
    "## Import files\n",
    "\n",
    "Here we'll import all the tools we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2fb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from operator import itemgetter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e5c7f",
   "metadata": {},
   "source": [
    "## Load and explore data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b273015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# read csv into dataframe\n",
    "df = pd.read_csv('../data/tweets.csv', encoding='unicode_escape')\n",
    "# show overview of data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102948a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show row and column counts\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a6a194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                            9065\n",
       "emotion_in_tweet_is_directed_at                          9\n",
       "is_there_an_emotion_directed_at_a_brand_or_product       4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show how many unique values for each feature\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089765f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion_in_tweet_is_directed_at\n",
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show value counts for one feature\n",
    "df.emotion_in_tweet_is_directed_at.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5837d898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "No emotion toward brand or product    0.59\n",
       "Positive emotion                      0.33\n",
       "Negative emotion                      0.06\n",
       "I can't tell                          0.02\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show value counts for one feature\n",
    "round(df.is_there_an_emotion_directed_at_a_brand_or_product.value_counts(normalize=True),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab5a686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "No emotion toward brand or product    0.91\n",
       "Positive emotion                      0.05\n",
       "I can't tell                          0.03\n",
       "Negative emotion                      0.01\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show breakdown of sentiment labels for tweets that have no product or brand identified\n",
    "round(df[df.emotion_in_tweet_is_directed_at.isna()] \\\n",
    ".is_there_an_emotion_directed_at_a_brand_or_product.value_counts(normalize=True),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c5a9fa",
   "metadata": {},
   "source": [
    "## Summary of data\n",
    "\n",
    "There are 9,093 records and three features. It appears that there are some duplicate tweets. For our purposes, even if there were multiple tweets that happened to be identical by chance (rather than duplicated by error), we still don't need both of them.\n",
    "\n",
    "A little more than one third (3,291) of the tweets are identified as being directed at a particular product or brand associated with either Google or Apple, while the majority do not identify a product or brand.\n",
    "\n",
    "Relatively few records have been identified as having a negative or \"I can't tell\" emotion.\n",
    "\n",
    "For the 5,802 records that don't identify a product or brand, about 9% of them were identified as having something other than \"no emotion\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc215ad",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "## Renaming features\n",
    "\n",
    "The column names are a bit cumbersome, so we'll give them new names that are easier to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "072b7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df.rename(columns={'tweet_text': 'text',\n",
    "                   'emotion_in_tweet_is_directed_at': 'brand',\n",
    "                   'is_there_an_emotion_directed_at_a_brand_or_product': 'sentiment'},\n",
    "          inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d82be9",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e10aac6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text brand                           sentiment\n",
       "6  NaN   NaN  No emotion toward brand or product"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show records with missing text\n",
    "df[df.text.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9590b0",
   "metadata": {},
   "source": [
    "We can't do anything with a record whose text is missing, so we'll drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16879e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop records with missing text values\n",
    "df.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb21d0",
   "metadata": {},
   "source": [
    "## Merge labels and standardize text to lower case\n",
    "\n",
    "As these tasks may increase the number of duplicate records, we should perform them before we look for those duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f04b58",
   "metadata": {},
   "source": [
    "### Lower case\n",
    "\n",
    "It's not likely that we'll lose anything important by shifting all the text to lower case, especially given the nature of tweeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7437a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift all text to lower case\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3e2f3",
   "metadata": {},
   "source": [
    "### Merge sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a19bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "No emotion toward brand or product    0.59\n",
       "Positive emotion                      0.33\n",
       "Negative emotion                      0.06\n",
       "I can't tell                          0.02\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show breakdown of sentiment before merging\n",
    "round(df.sentiment.value_counts(normalize=True),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227de466",
   "metadata": {},
   "source": [
    "In order to reduce the class imbalance and generally simplify the work, we'll change the sentiment labels to a binary system of 1 for positive and 0 for everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4c5b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sentiment binary\n",
    "df['sentiment'].replace({'No emotion toward brand or product': 0,\n",
    "                         'Positive emotion': 1,\n",
    "                         'Negative emotion': 0,\n",
    "                         \"I can't tell\": 0\n",
    "                        }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0c6116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    0.67\n",
       "1    0.33\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show breakdown of sentiment after merging\n",
    "round(df.sentiment.value_counts(normalize=True),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0582b7",
   "metadata": {},
   "source": [
    "### Merge brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e022e86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand\n",
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show breakdown of brand before merging\n",
    "df.brand.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1053a6",
   "metadata": {},
   "source": [
    "# POSSIBLE COMMENT OR CHANGE IN STRATEGY HERE DEPENDING ON BUSINESS PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d16200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign either apple or google label and fill in missing values with other\n",
    "df['brand'].replace(['iPad', 'Apple', 'iPad or iPhone App', 'iPhone', 'Other Apple product or service'], 'apple',\n",
    "                     inplace=True)\n",
    "df['brand'].replace(['Google', 'Other Google product or service', 'Android App', 'Android'], 'google',\n",
    "                     inplace=True)\n",
    "df['brand'].fillna('other',\n",
    "                    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1ae5d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand\n",
       "other     5801\n",
       "apple     2409\n",
       "google     882\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show breakdown of brand after merging\n",
    "df.brand.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7970ab",
   "metadata": {},
   "source": [
    "deal with missing company\n",
    "missing company values are informed by the text, and the text should be all lower case to simplify this\n",
    "no big deal because we want all lower case for train and test anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a25a3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make key word lists for apple and google\n",
    "apple_words = ['ipad', 'apple', 'iphone', 'itunes', 'ipad2']\n",
    "google_words = ['google', 'android', 'blogger']\n",
    "\n",
    "# make a function that relabels brand values by finding what keywords are mentioned in the text\n",
    "def brand_fix(text, brand):\n",
    "    # only relabel records that do not have one of the two brands already associated\n",
    "    if brand != 'other':\n",
    "        return brand\n",
    "    else:\n",
    "        apple, google = False, False\n",
    "        # look for apple keyword\n",
    "        for word in apple_words:\n",
    "            if word in text:\n",
    "                apple = True\n",
    "                break\n",
    "        # look for google keyword\n",
    "        for word in google_words:\n",
    "            if word in text:\n",
    "                google = True\n",
    "                break\n",
    "\n",
    "        # return correct new label\n",
    "        if apple & ~google:\n",
    "            return 'apple'\n",
    "        elif google & ~apple:\n",
    "            return 'google'\n",
    "        elif apple & google:\n",
    "            return 'both'\n",
    "        else:\n",
    "            return 'neither'\n",
    "\n",
    "# run above function to relabel brand values\n",
    "df['brand'] = df.apply(lambda x: brand_fix(x.text, x.brand), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ace2ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand\n",
       "apple      5396\n",
       "google     2804\n",
       "neither     704\n",
       "both        188\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show breakdown of brand after running function\n",
    "df.brand.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e313a",
   "metadata": {},
   "source": [
    "# CONSIDER REVISITING NEITHER AND BOTH DEPENDING ON BUSINESS PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debdad7f",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcaaa2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9050\n",
       "True       42\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show how many records are duplicates\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a827c7d7",
   "metadata": {},
   "source": [
    "We'll drop any duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19e335bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate records\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ab3675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9047\n",
       "True        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show how many records are duplicates for the text value only\n",
    "df.duplicated(subset=['text']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb8e678",
   "metadata": {},
   "source": [
    "Curiously, 3 records are identified as duplicate text values that evidently have different values for other features. Let's see if those records differ on sentiment identification. (It's less important whether they differ on brand identification.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eebaba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate group 1 \n",
      " win free ipad 2 from webdoc.com #sxsw rt \n",
      "\n",
      " sentiment\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 2 \n",
      " rt @mention marissa mayer: google will connect the digital &amp; physical worlds through mobile - {link} #sxsw \n",
      "\n",
      " sentiment\n",
      "1    1\n",
      "0    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 3 \n",
      " rt @mention rt @mention it's not a rumor: apple is opening up a temporary store in downtown austin for #sxsw and the ipad 2 launch {link} \n",
      "\n",
      " sentiment\n",
      "1    1\n",
      "0    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show sentiment identification for groups of duplicated tweets\n",
    "for i, index in enumerate(df[df.duplicated(subset=['text'])].index):\n",
    "    print(\n",
    "        'duplicate group', i+1, '\\n',\n",
    "        df.loc[index].text, '\\n\\n',\n",
    "        df[df.text == df.loc[index].text].sentiment.value_counts(),\n",
    "        '\\n\\n- - - -\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4330a9",
   "metadata": {},
   "source": [
    "Each duplicated tweet has been labeled once as positive and once as nonpositive. It seems fair to keep the positive labels for each of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7bc4169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over records listed as duplicates\n",
    "for i in df[df.duplicated(subset=['text'])].index:\n",
    "    # drop any records whose text matches a particular duplicate AND is labeled nonpositive\n",
    "    df.drop(df[ (df.text == df.loc[i].text) & (df.sentiment == 0) ].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce50a09",
   "metadata": {},
   "source": [
    "## Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "923934be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into target (sentiment) and predictor (text)\n",
    "X, y = df['text'].to_frame(), df['sentiment']\n",
    "# split the data into train and test sets\n",
    "# set random state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad329b",
   "metadata": {},
   "source": [
    "# REVISIT THIS\n",
    "\n",
    "add label to X_train for research purposes .. obviously don't include this in the model\n",
    "\n",
    "reset index to anticipate future problems ... or not reset the index???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "581a3b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-9e81947b441d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, 'sentiment'] = [y_train.loc[val] for val in X_train.index]\n"
     ]
    }
   ],
   "source": [
    "X_train.loc[:, 'sentiment'] = [y_train.loc[val] for val in X_train.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2dcbc",
   "metadata": {},
   "source": [
    "## Tokenize\n",
    "\n",
    "We'll establish a token pattern that will separate each tweet into a list of tokens at least 2 letters long and ignore punctuation characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a1a7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tokenizer\n",
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57e21c",
   "metadata": {},
   "source": [
    "We'll make a new column whose values will be the list of tokens from each text value. Then we can group these tokens/words together into a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0214f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw vocabulary: 8858\n"
     ]
    }
   ],
   "source": [
    "# create feature of tokenized text\n",
    "X_train.loc[:, 'text_tokenized'] = X_train['text'].apply(tokenizer.tokenize)\n",
    "# make vocabulary from set of words\n",
    "vocab_raw = set(X_train['text_tokenized'].explode())\n",
    "# show size of raw vocabulary\n",
    "print('Size of raw vocabulary:', len(vocab_raw))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd5113f",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## Baseline model\n",
    "\n",
    "We'll use multinomial naive Bayes for our baseline model and feed it the 10 most common tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99f3376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "baseline_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab474ede",
   "metadata": {},
   "source": [
    "It will be instructive to recall the percentage of the plurality in the target feature (sentiment). Models should be evaluated in relation to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9692895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    0.6695\n",
       "1    0.3305\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save this value to compare to future model crossval scores\n",
    "plurality_cv = round(y_train.value_counts(normalize=True)[0],4)\n",
    "# show the sentiment breakdown\n",
    "round(y_train.value_counts(normalize=True),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ce1b3",
   "metadata": {},
   "source": [
    "Accuracy of future models should exceed the higher of these values, since we know that, at worst, a model could just predict all sentiments are \"nonpositive\" and achieve this score.\n",
    "\n",
    "We'll run the first model and compare the score to this plurality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab9c07de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality: 0.6695 \n",
      "Baseline:  0.6695\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features = 10\n",
    ")\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text'])\n",
    "\n",
    "baseline_cv = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "\n",
    "print('Plurality:', plurality_cv,\n",
    "      '\\nBaseline: ',baseline_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75732f4",
   "metadata": {},
   "source": [
    "This did not improve on plurality at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098aeb1d",
   "metadata": {},
   "source": [
    "## All words model\n",
    "\n",
    "We'll see if anything changes when we feed the model all possible tokens rather than just the 10 most common ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8203c4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality: 0.6695 \n",
      "Baseline:  0.6695 \n",
      "All Words: 0.7011\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    ")\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text'])\n",
    "\n",
    "all_words_cv = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "\n",
    "print('Plurality:', plurality_cv,\n",
    "      '\\nBaseline: ',baseline_cv,\n",
    "      '\\nAll Words:',all_words_cv\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cebb99",
   "metadata": {},
   "source": [
    "This did indeed improve the accuracy.\n",
    "\n",
    "## Stemmed and lemmatized model\n",
    "\n",
    "Now we'll stem and lemmatize the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cdc0f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a stemmer and lemmatizer\n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08a251cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function that tokenizes, stems and lemmatizes a document\n",
    "def stem_and_lemmatize_and_tokenize(document):\n",
    "    tokens = tokenizer.tokenize(document)\n",
    "    return [lemmatizer.lemmatize(stemmer.stem(token)) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cfa01ac2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw vocabulary:                    8858 \n",
      "Size of stemmed and lemmatized vocabulary: 6965\n"
     ]
    }
   ],
   "source": [
    "# create a column whose values are a list of stemmed and lemmatized words\n",
    "X_train.loc[:, 'stem_lemma_list'] = X_train.loc[:, 'text'].apply(stem_and_lemmatize_and_tokenize)\n",
    "# make vocabulary from set of words\n",
    "vocab_stemmed_and_lemmatized = set(X_train['stem_lemma_list'].explode())\n",
    "# compare vocabulary sizes\n",
    "print('Size of raw vocabulary:                   ', len(vocab_raw),\n",
    "      '\\nSize of stemmed and lemmatized vocabulary:', len(vocab_stemmed_and_lemmatized)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fd8d2",
   "metadata": {},
   "source": [
    "The stemmed and lemmatized vocabulary is significantly smaller. We can now investigate whether this has introduced new duplicate values for the stemmed and lemmatized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70eeec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(word_list):\n",
    "    string = ''\n",
    "    for word in word_list:\n",
    "        string = string + word + ' '\n",
    "    return string[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b4a039e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-91f45a5a7bce>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['text_stemmed_and_lemmatized'] = X_train['stem_lemma_list'].apply(lambda x: stringify(x))\n"
     ]
    }
   ],
   "source": [
    "X_train['text_stemmed_and_lemmatized'] = X_train['stem_lemma_list'].apply(lambda x: stringify(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ffea59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:                     0.6695 \n",
      "All Words:                    0.7011 \n",
      "Stemmed and Lemmatized Words: 0.6986\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text_stemmed_and_lemmatized'])\n",
    "\n",
    "stemmed_and_lemmatized_words_cv = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "\n",
    "print('Baseline:                    ',baseline_cv,\n",
    "      '\\nAll Words:                   ',all_words_cv,\n",
    "      '\\nStemmed and Lemmatized Words:', stemmed_and_lemmatized_words_cv\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8df3a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    7148\n",
       "True       89\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.duplicated(subset=['text_stemmed_and_lemmatized']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28354e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate group 1 \n",
      " gear up to make splash mention to launch quot groupon or live social type quot reward at sxsw link \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 2 \n",
      " rt mention don worri you guy found an iphon charger what the deal with hipster and beard right sxsw \n",
      "\n",
      " sentiment\n",
      "1    1\n",
      "0    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 3 \n",
      " you final get everyon to buy in to facebook and then googl introduc circl no fair stop with all the innov peopl sxsw \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 4 \n",
      " googl to launch major new social network call circl possibl today link sxsw \n",
      "\n",
      " sentiment\n",
      "0    6\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 5 \n",
      " rt mention googl to launch major new social network call circl possibl today link sxsw twnp socmedia \n",
      "\n",
      " sentiment\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 6 \n",
      " rt mention reaction to googl circl news so far rang from quot not again quot to quot plea rescu me from the facebook quot sxsw \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 7 \n",
      " googl to launch major new social network call circl possibl today link sxsw \n",
      "\n",
      " sentiment\n",
      "0    6\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 8 \n",
      " googl to launch major new social network call circl possibl today link sxsw \n",
      "\n",
      " sentiment\n",
      "0    6\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 9 \n",
      " rt mention if you were abl to afford to attend sxsw or buy an ipad today consid save few for japan earthquak relief \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 10 \n",
      " free quot payment on the android platform quot webinar on march 30th regist today link sxsw mr \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 11 \n",
      " congrat rt mention yes gowalla win best andoid app at the team android choic award thank all sxsw \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 12 \n",
      " appl to open pop up shop at sxsw report link sxsw \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 13 \n",
      " rt mention googl to launch major new social network call circl possibl today link sxsw \n",
      "\n",
      " sentiment\n",
      "0    5\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 14 \n",
      " mention enjoy sxsw and ride anywher in austin for 10 download the groundlink app link booth 437 \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 15 \n",
      " rt mention rt mention love it mention sxsw quot appl come up with cool technolog no one ever heard of becaus they don go to confer quot \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 16 \n",
      " quot mention googl to launch major new social network call circl possibl today link sxsw quot \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 17 \n",
      " at sxsw appl school the market expert link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 18 \n",
      " rt mention rt mention travel to sxsw with your ipad is so 10 2011 \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 19 \n",
      " cc mention rt mention new ubersoci for iphon now in the app store includ uberguid to sxsw cont link \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 20 \n",
      " appl set to open popup shop in core of sxsw action in downtown austin link ipad \n",
      "\n",
      " sentiment\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 21 \n",
      " rt mention new ubersoci for iphon now in the app store includ uberguid to sxsw sponsor by mashabl link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 22 \n",
      " sxsw crowd swarm for ipad launch link via mention \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 23 \n",
      " rt mention quot googl befor you tweet quot is the new quot think befor you speak quot mark belinski 911tweet panel at sxsw \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 24 \n",
      " rt mention new ubersoci for iphon now in the app store includ uberguid to sxsw sponsor by mashabl link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 25 \n",
      " googl to launch major new social network call circl possibl today link sxsw \n",
      "\n",
      " sentiment\n",
      "0    6\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 26 \n",
      " omarg it not rumor appl is open up temporari store in downtown austin for sxsw and the ipad launch link \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 27 \n",
      " rt mention googl to launch major new social network call circl possibl today link sxsw \n",
      "\n",
      " sentiment\n",
      "0    5\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 28 \n",
      " mention saw go to sxsw dwnld groundlink app amp ride for 10 in austin dure sxswi link see u booth 437 \n",
      "\n",
      " sentiment\n",
      "0    3\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 29 \n",
      " nice rt mention hey appl fan get peek at the space that slate to be pop up sxsw appl store tomorrow link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 30 \n",
      " quot mention new ubersoci for iphon now in the app store includ uberguid to sxsw sponsor by mashabl link \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 31 \n",
      " win an ipad at sxsw via mention sxsw link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 32 \n",
      " rt mention got crave sxsw mind creat an app for that foodspot link iphon app \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 33 \n",
      " rt mention best thing ve heard this weekend at sxsw quot gave my ipad money to japan relief don need an ipad quot \n",
      "\n",
      " sentiment\n",
      "0    3\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 34 \n",
      " rt mention googl to launch major new social network call circl possibl today link sxsw via mention \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 35 \n",
      " doe your smallbiz need review to play on googl place we got an app for that link seo sxsw \n",
      "\n",
      " sentiment\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 36 \n",
      " rt mention googl to launch major new social network call circl possibl today link sxsw mention \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 37 \n",
      " how to improv websit rank advic from googl and bing at sxsw poynter link \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 38 \n",
      " appl to open pop up shop at sxsw link \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 39 \n",
      " mention googl will connect the digit amp physic world through mobil link sxsw rt mention \n",
      "\n",
      " sentiment\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 40 \n",
      " rt mention best thing ve heard this weekend at sxsw quot gave my ipad money to japan relief don need an ipad quot \n",
      "\n",
      " sentiment\n",
      "0    3\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 41 \n",
      " googl latina and see what you find porn this is the first impress that peopl get about u latism sxsw sxswlatam latinasintech \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 42 \n",
      " rt mention new ubersoci for iphon now in the app store includ uberguid to sxsw sponsor by mashabl link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 43 \n",
      " rt mention it not rumor appl is open up temporari store in downtown austin for sxsw and the ipad2 launch link \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 44 \n",
      " pubcamp kirkus sxsw download qrank on your ipad iphon befor you come to pubcamp sxsw 2011 prize \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 45 \n",
      " mention welcom enjoy sxsw and ride anywher in austin for 10 dwnld the groundlink app link booth 437 \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 46 \n",
      " googl to launch major new social network call circl possibl today by mention link via mention sxsw screenfutur \n",
      "\n",
      " sentiment\n",
      "1    1\n",
      "0    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 47 \n",
      " check out design ipad interfac new navig schema at sxsw link sxsw uxd \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 48 \n",
      " googl to launch major new social network call circl link sxsw \n",
      "\n",
      " sentiment\n",
      "0    3\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 49 \n",
      " rt mention googl to launch major new social network call circl possibl today link sxsw \n",
      "\n",
      " sentiment\n",
      "0    5\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 50 \n",
      " rt mention googl new quot rout around quot featur give altern rout to avoid traffic collect save driver yr day sxsw \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 51 \n",
      " appl to open pop up shop at sxsw report link \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 52 \n",
      " googl to launch major new social network call circl googl circl sxsw link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 53 \n",
      " the ipad take over sxsw video link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 54 \n",
      " mention saw go to sxsw dwnld groundlink app amp ride for 10 in austin dure sxswi link see u booth 437 \n",
      "\n",
      " sentiment\n",
      "0    3\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 55 \n",
      " rt mention rt mention love it mention at sxsw quot appl come up with cool technolog no one ever heard of becaus they don go to confer quot \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 56 \n",
      " googl to launch major new social network call circl link sxsw \n",
      "\n",
      " sentiment\n",
      "0    3\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 57 \n",
      " mention hello enjoy sxsw and ride anywher in austin for 10 download the groundlink app link booth 437 \n",
      "\n",
      " sentiment\n",
      "1    1\n",
      "0    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 58 \n",
      " googl to launch major new social network call circl possibl today link sxsw \n",
      "\n",
      " sentiment\n",
      "0    6\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 59 \n",
      " rt mention team head to big boi show thank to mention crew rt and find the owl for free tattoo link sxsw \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 60 \n",
      " rt mention it not rumor appl is open up temporari store in downtown austin for sxsw and the ipad launch link \n",
      "\n",
      " sentiment\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 61 \n",
      " marissa mayer googl will connect the digit amp physic world through mobil link sxsw \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 62 \n",
      " googl to launch major new social network call circl possibl today link sxsw mention \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 63 \n",
      " rt mention yes updat iphon app ha song info mention 24 stream other also live video stream for sxsw link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 64 \n",
      " rt mention rt mention quot googl befor you tweet quot is the new quot think befor you speak quot mark belinski 911tweet panel at sxsw \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 65 \n",
      " rt mention free quot payment on the android platform quot webinar on march 30th regist today link sxsw mr \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 66 \n",
      " rt mention googl to launch major new social network call circl possibl today at sxsw link \n",
      "\n",
      " sentiment\n",
      "1    1\n",
      "0    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 67 \n",
      " rt mention we interrupt your regular schedul sxsw geek program with big news link googl circl \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 68 \n",
      " rt mention mention mention amp mention have fun at googl pic sxsw link \n",
      "\n",
      " sentiment\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 69 \n",
      " mention fals alarm googl circl not come now ûòand probabl not ever link googl circl social sxsw \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 70 \n",
      " sxsw mistak made build netflix for iphon plus how to see it sourc code link \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 71 \n",
      " hootsuit blog ûò social medium dashboard åè hootsuit mobil for sxsw updat for iphon blackberri amp android link \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 72 \n",
      " rt mention googl to launch major new social network call circl possibl today link sxsw \n",
      "\n",
      " sentiment\n",
      "0    5\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 73 \n",
      " at sxsw appl school the market expert link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 74 \n",
      " rt mention left my white iphon 4g in cab in austin at sxsw internet plea help \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 75 \n",
      " googl map street view car sight sxsw link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 76 \n",
      " check out stay aliv can indi iphon game develop surviv at sxsw stayingal \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 77 \n",
      " rt mention we interrupt your regular schedul sxsw geek program with big news link googl circl \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 78 \n",
      " win free ipad from webdoc com sxsw rt \n",
      "\n",
      " sentiment\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 79 \n",
      " rt mention rt mention best thing ve heard this weekend at sxsw quot gave my ipad money to japan relief don need an ipad quot mention \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 80 \n",
      " switch to the offic ipad for this next session on flipboard gamechang or pas fad mention should like this one sxsw \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 81 \n",
      " rt mention with 150 million mobil user on googl map 40 of all googl map usag is from mobil devic map sxsw \n",
      "\n",
      " sentiment\n",
      "1    1\n",
      "0    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 82 \n",
      " will googl circl take on facebook link circl sxsw \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 83 \n",
      " score free imo tshirt outsid the sxsw appl store today at 15 pm amp check out imo app for the ipad link sxsw ipad2 \n",
      "\n",
      " sentiment\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 84 \n",
      " at sxsw appl school the market expert link \n",
      "\n",
      " sentiment\n",
      "1    2\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 85 \n",
      " per this rumor googl may preview it big social strategi at an 80 theme costum parti at sxsw yep link cnet \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 86 \n",
      " will googl reveal new social network call circl googl facebook twitter sxsw link via mention \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 87 \n",
      " hootsuit mobil for sxsw updat for iphon blackberri amp android link via mention \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 88 \n",
      " rt mention will googl circl take on facebook link circl sxsw \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n",
      "duplicate group 89 \n",
      " rt mention rt mention we interrupt your regular schedul sxsw geek program with big news link googl circl \n",
      "\n",
      " sentiment\n",
      "0    2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "- - - -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show sentiment identification for groups of duplicated tweets\n",
    "for i, index in enumerate(X_train[X_train.duplicated(subset=['text_stemmed_and_lemmatized'])].index):\n",
    "    print(\n",
    "        'duplicate group', i+1, '\\n',\n",
    "        X_train.loc[index].text_stemmed_and_lemmatized, '\\n\\n',\n",
    "        X_train[X_train.text_stemmed_and_lemmatized == X_train.loc[index].text_stemmed_and_lemmatized].sentiment.value_counts(),\n",
    "        '\\n\\n- - - -\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ef7b8",
   "metadata": {},
   "source": [
    "# WHAT TO DO ABOUT NEW DUPLICATES?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93c58c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality:                    0.6695 \n",
      "Stemmed and Lemmatized Words: 0.722\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    min_df = 2,\n",
    "    max_df = .02\n",
    ")\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text_stemmed_and_lemmatized'])\n",
    "\n",
    "stemmed_and_lemmatized_words_cv = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "\n",
    "print('Plurality:                   ', plurality_cv,\n",
    "      '\\nStemmed and Lemmatized Words:', stemmed_and_lemmatized_words_cv\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
