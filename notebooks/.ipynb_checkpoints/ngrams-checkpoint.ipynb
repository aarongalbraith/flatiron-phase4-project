{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e593540b",
   "metadata": {},
   "source": [
    "# This version will explore ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cdd3bc",
   "metadata": {},
   "source": [
    "import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8c5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from operator import itemgetter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60439ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc638a",
   "metadata": {},
   "source": [
    "could do more here to explore the neither and both values\n",
    "\n",
    "move on to language processing\n",
    "\n",
    "train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0947d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['text'].to_frame(), df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b6de4",
   "metadata": {},
   "source": [
    "add label to X_train for research purposes .. obviously don't include this in the model\n",
    "\n",
    "reset index to anticipate future problems ... or not reset the index???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ffe232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-0cb08c382a27>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, 'label'] = [y_train.loc[val] for val in X_train.index]\n"
     ]
    }
   ],
   "source": [
    "X_train.loc[:, 'label'] = [y_train.loc[val] for val in X_train.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543eb41",
   "metadata": {},
   "source": [
    "perfunctory exploring should happen here\n",
    "\n",
    "top ten visualizations for pos. and non-pos.\n",
    "\n",
    "size of vocabulary\n",
    "\n",
    "more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30931e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5098fb",
   "metadata": {},
   "source": [
    "load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b524ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw vocabulary: 8876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-5ba9b3884ac5>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, 'text_tokenized'] = X_train['text'].apply(tokenizer.tokenize)\n"
     ]
    }
   ],
   "source": [
    "X_train.loc[:, 'text_tokenized'] = X_train['text'].apply(tokenizer.tokenize)\n",
    "vocab_raw = set(X_train['text_tokenized'].explode())\n",
    "print('Size of raw vocabulary:', len(vocab_raw))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060bb69f",
   "metadata": {},
   "source": [
    "gonna need naive bayes, might not do any other models (markov, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ea9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a5178a",
   "metadata": {},
   "source": [
    "look at plurality winner to see score to beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9fe88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    0.672366\n",
       "1    0.327634\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plurality_cv = round(y_train.value_counts(normalize=True)[0],4)\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c70b3",
   "metadata": {},
   "source": [
    "first model, just ten features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2a51d",
   "metadata": {},
   "source": [
    "let's try n-grams, n from 2 to 7, using all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d1aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngrams(word_list, n):\n",
    "    length = len(word_list)\n",
    "    if length < n:\n",
    "        return None\n",
    "    else:\n",
    "        ngram_list = []\n",
    "        for i in range(length - n + 1):\n",
    "            ngram = ''\n",
    "            for j in range(i, i+n):\n",
    "                if j > i:\n",
    "                    ngram += ' '\n",
    "                ngram += word_list[j]\n",
    "            ngram_list.append(ngram)\n",
    "        return ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd719c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-cd7379d45510>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, str(n)+'_grams'] = X_train.loc[:, 'text_tokenized'].apply(lambda x: make_ngrams(x, n))\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range = (n,n)\n",
    ")\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text'])\n",
    "\n",
    "score = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "\n",
    "feature_names = np.array(tfidf.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "\n",
    "\n",
    "# create array of the word list from this vectorizer with new index\n",
    "feature_names = np.array(tfidf.get_feature_names())\n",
    "# create array of the indices of the feature_names array, ordered by tfidf score\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "X_train.loc[:, str(n)+'_grams'] = X_train.loc[:, 'text_tokenized'].apply(lambda x: make_ngrams(x, n))\n",
    "\n",
    "# create frequency distribution (dictionary) of 1-grams\n",
    "bigrams_freq_dist = FreqDist(X_train['text_tokenized'].explode())\n",
    "\n",
    "bigrams = X_train.loc[:, str(n)+'_grams'].explode()\n",
    "bigrams_freq_dist = FreqDist(bigrams)\n",
    "    \n",
    "#     smallest.append(feature_names[sorted_tfidf_index[:10]])\n",
    "#     largest.append(feature_names[sorted_tfidf_index[:-11:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b5773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 mention sxsw ipad rocks\n",
      "1.0 my sxsw iphone screen\n",
      "1.0 worship mention link sxsw\n",
      "1.0 essential sxsw tools link\n",
      "1.0 iphone sharing sxsw shareable\n",
      "1.0 google circles sxsw orly\n",
      "0.8038 at apple store at\n",
      "0.7342 ipad line sxsw link\n",
      "0.7229 in hand sxsw thisisdare\n",
      "0.7229 covet new ipad link\n"
     ]
    }
   ],
   "source": [
    "# show the words with the top 10 tfidf values, and their tfidf values\n",
    "for n in range(-1,-11,-1):\n",
    "    print(round(X_train_vectorized.max(0).toarray()[0][sorted_tfidf_index[n]],4),\n",
    "          feature_names[sorted_tfidf_index[n]]\n",
    "         )      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e609136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram score: 0.7005\n",
      "2-gram score: 0.7117\n",
      "3-gram score: 0.7159\n",
      "4-gram score: 0.7159\n",
      "5-gram score: 0.7137\n",
      "6-gram score: 0.7121\n",
      "7-gram score: 0.7108\n"
     ]
    }
   ],
   "source": [
    "smallest, largest = [], []\n",
    "\n",
    "for n in range(1,8):\n",
    "    \n",
    "    if n > 1:\n",
    "        tfidf = TfidfVectorizer(\n",
    "            ngram_range = (n,n)\n",
    "        )\n",
    "    else:\n",
    "        tfidf = TfidfVectorizer()\n",
    "    \n",
    "    X_train_vectorized = tfidf.fit_transform(X_train['text'])\n",
    "    \n",
    "    score = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "    \n",
    "    print(str(n)+'-gram', 'score:', score)\n",
    "\n",
    "    feature_names = np.array(tfidf.get_feature_names())\n",
    "\n",
    "    sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "    \n",
    "    smallest.append(feature_names[sorted_tfidf_index[:10]])\n",
    "    largest.append(feature_names[sorted_tfidf_index[:-11:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd1f54",
   "metadata": {},
   "source": [
    "top ten only looks at top ten most frequent, so this is useless until you give it a stop words list, probably not useful at all\n",
    "\n",
    "now i have a way to find the top and bottom tfidf scores, i need to take this one step further to see how frequent those terms are, this will help me to decide to ignore n > 4 for example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d1b59",
   "metadata": {},
   "source": [
    "I will make a function to use with lambda to generate a column of ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c9bb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngrams(word_list, n):\n",
    "    length = len(word_list)\n",
    "    if length < n:\n",
    "        return None\n",
    "    else:\n",
    "        ngram_list = []\n",
    "        for i in range(length - n + 1):\n",
    "            ngram = ''\n",
    "            for j in range(i, i+n):\n",
    "                if j > i:\n",
    "                    ngram += ' '\n",
    "                ngram += word_list[j]\n",
    "            ngram_list.append(ngram)\n",
    "        return ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07cadfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-285e0fd66593>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, title] = X_train.loc[:, 'text_tokenized'].apply(lambda x: make_ngrams(x, n))\n"
     ]
    }
   ],
   "source": [
    "# it might stop throwing an error if you FIRST establish these columns, THEN assign values to them??\n",
    "for n in range(3,4):\n",
    "    title = str(n) + '_grams'\n",
    "    X_train.loc[:, title] = X_train.loc[:, 'text_tokenized'].apply(lambda x: make_ngrams(x, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "430efaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new social network',\n",
       "  'pop up store',\n",
       "  'at sxsw link',\n",
       "  'social network called',\n",
       "  'network called circles',\n",
       "  'google to launch',\n",
       "  'major new social',\n",
       "  'launch major new',\n",
       "  'to launch major',\n",
       "  'rt mention google'),\n",
       " (311, 277, 273, 258, 249, 242, 232, 227, 218, 215)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = X_train.loc[:, '3_grams'].explode()\n",
    "all_words_freq_dist = FreqDist(all_words)\n",
    "\n",
    "all_words_set = set(all_words)\n",
    "\n",
    "all_words_ordered = list(zip(*all_words_freq_dist.most_common(10)))\n",
    "\n",
    "all_words_ordered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
