{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a110b3b",
   "metadata": {},
   "source": [
    "# This version scores the basic models:\n",
    "- baseline (top ten)\n",
    "- all words\n",
    "- stemmed words\n",
    "- lemmatized words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97db32e7",
   "metadata": {},
   "source": [
    "import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1dae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from operator import itemgetter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e47b6",
   "metadata": {},
   "source": [
    "load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2871535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a7b88a",
   "metadata": {},
   "source": [
    "could do more here to explore the neither and both values\n",
    "\n",
    "move on to language processing\n",
    "\n",
    "train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50ecdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['text'].to_frame(), df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab183fb3",
   "metadata": {},
   "source": [
    "add label to X_train for research purposes .. obviously don't include this in the model\n",
    "\n",
    "reset index to anticipate future problems ... or not reset the index???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cac3b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-0cb08c382a27>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, 'label'] = [y_train.loc[val] for val in X_train.index]\n"
     ]
    }
   ],
   "source": [
    "X_train.loc[:, 'label'] = [y_train.loc[val] for val in X_train.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373694cd",
   "metadata": {},
   "source": [
    "perfunctory exploring should happen here\n",
    "\n",
    "top ten visualizations for pos. and non-pos.\n",
    "\n",
    "size of vocabulary\n",
    "\n",
    "more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c59cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712f9874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw vocabulary: 8876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-5ba9b3884ac5>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, 'text_tokenized'] = X_train['text'].apply(tokenizer.tokenize)\n"
     ]
    }
   ],
   "source": [
    "X_train.loc[:, 'text_tokenized'] = X_train['text'].apply(tokenizer.tokenize)\n",
    "vocab_raw = set(X_train['text_tokenized'].explode())\n",
    "print('Size of raw vocabulary:', len(vocab_raw))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a7b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(word_list):\n",
    "    string = ''\n",
    "    for word in word_list:\n",
    "        string = string + word + ' '\n",
    "    return string[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2c2a8b",
   "metadata": {},
   "source": [
    "gonna need naive bayes, might not do any other models (markov, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4425bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6163283",
   "metadata": {},
   "source": [
    "look at plurality winner to see score to beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e96f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    0.672366\n",
       "1    0.327634\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plurality_cv = round(y_train.value_counts(normalize=True)[0],4)\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ca29a",
   "metadata": {},
   "source": [
    "first model, just ten features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2881bba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality: 0.6724 \n",
      "Baseline:  0.6724\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features = 10\n",
    ")\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text'])\n",
    "\n",
    "baseline_cv = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "\n",
    "print('Plurality:', plurality_cv,\n",
    "      '\\nBaseline: ',baseline_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d86d194",
   "metadata": {},
   "source": [
    "an absolutely miniscule improvement\n",
    "\n",
    "let's try all words, not just max_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa44222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality: 0.6724 \n",
      "Baseline:  0.6724 \n",
      "All Words: 0.7005\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text'])\n",
    "\n",
    "all_words_cv = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "\n",
    "print('Plurality:', plurality_cv,\n",
    "      '\\nBaseline: ', baseline_cv,\n",
    "      '\\nAll Words:', all_words_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397a1ea",
   "metadata": {},
   "source": [
    "an actual improvement\n",
    "\n",
    "let's look at which 10 terms were least and most associated with positive sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7858c06",
   "metadata": {},
   "source": [
    "we can and will explore stopwords, but it seems clear we can stem or lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee29a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "\n",
    "def stem_and_tokenize(document):\n",
    "    tokens = tokenizer.tokenize(document)\n",
    "    return [stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac88a7f",
   "metadata": {},
   "source": [
    "create stemmed vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ca9ce5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw vocabulary:     8876\n",
      "Size of stemmed vocabulary: 7016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-35732fed5f8f>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, 'stem_list'] = X_train.loc[:, 'text'].apply(stem_and_tokenize)\n"
     ]
    }
   ],
   "source": [
    "X_train.loc[:, 'stem_list'] = X_train.loc[:, 'text'].apply(stem_and_tokenize)\n",
    "vocab_stemmed = set(X_train['stem_list'].explode())\n",
    "print('Size of raw vocabulary:    ', len(vocab_raw))\n",
    "print('Size of stemmed vocabulary:', len(vocab_stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcb40606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-d12234a2fa67>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['text_stemmed'] = X_train['stem_list'].apply(lambda x: stringify(x))\n"
     ]
    }
   ],
   "source": [
    "X_train['text_stemmed'] = X_train['stem_list'].apply(lambda x: stringify(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11448f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality:     0.6724 \n",
      "Baseline:      0.6724 \n",
      "All Words:     0.7005 \n",
      "Stemmed Words: 0.6995\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text_stemmed'])\n",
    "\n",
    "stemmed_words_cv = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "\n",
    "print('Plurality:    ', plurality_cv,\n",
    "      '\\nBaseline:     ', baseline_cv,\n",
    "      '\\nAll Words:    ', all_words_cv,\n",
    "      '\\nStemmed Words:', stemmed_words_cv\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12a2b5",
   "metadata": {},
   "source": [
    "Stemming is worse by about one tenth of a percent\n",
    "\n",
    "top 10 terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc9ff878",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_and_tokenize(document):\n",
    "    tokens = tokenizer.tokenize(document)\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fa6c4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw vocabulary:        8876 \n",
      "Size of stemmed vocabulary:    7016 \n",
      "Size of lemmatized vocabulary: 8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-2d8313eb70c2>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, 'lemma_list'] = X_train.loc[:, 'text'].apply(lemmatize_and_tokenize)\n"
     ]
    }
   ],
   "source": [
    "X_train.loc[:, 'lemma_list'] = X_train.loc[:, 'text'].apply(lemmatize_and_tokenize)\n",
    "vocab_lemmatized = set(X_train['lemma_list'].explode())\n",
    "print('Size of raw vocabulary:       ', len(vocab_raw),\n",
    "      '\\nSize of stemmed vocabulary:   ', len(vocab_stemmed),\n",
    "      '\\nSize of lemmatized vocabulary:', len(vocab_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7326157e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-a67b2dff99dc>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['text_lemmatized'] = X_train['lemma_list'].apply(lambda x: stringify(x))\n"
     ]
    }
   ],
   "source": [
    "X_train['text_lemmatized'] = X_train['lemma_list'].apply(lambda x: stringify(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb26afb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality:        0.6724 \n",
      "All Words:        0.7005 \n",
      "Stemmed Words:    0.6995 \n",
      "Lemmatized Words: 0.6986\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text_lemmatized'])\n",
    "\n",
    "lemmatized_words_cv = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "\n",
    "print('Plurality:       ', plurality_cv,\n",
    "      '\\nAll Words:       ', all_words_cv,\n",
    "      '\\nStemmed Words:   ', stemmed_words_cv,\n",
    "      '\\nLemmatized Words:', lemmatized_words_cv\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6230a",
   "metadata": {},
   "source": [
    "lemmatizing makes it worse by another tenth of a percent\n",
    "\n",
    "look at top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba54122",
   "metadata": {},
   "source": [
    "top ten only looks at top ten most frequent, so this is useless until you give it a stop words list, probably not useful at all\n",
    "\n",
    "now i have a way to find the top and bottom tfidf scores, i need to take this one step further to see how frequent those terms are, this will help me to decide to ignore n > 4 for example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a22dd7",
   "metadata": {},
   "source": [
    "getting absolutely nowhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc479123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_and_lemmatize_and_tokenize(document):\n",
    "    tokens = tokenizer.tokenize(document)\n",
    "    return [lemmatizer.lemmatize(stemmer.stem(token)) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c011c11c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw vocabulary:                    8876 \n",
      "Size of stemmed vocabulary:                7016 \n",
      "Size of lemmatized vocabulary:             8208 \n",
      "Size of stemmed and lemmatized vocabulary: 6984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-9ee0fef53168>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, 'stem_lemma_list'] = X_train.loc[:, 'text'].apply(stem_and_lemmatize_and_tokenize)\n"
     ]
    }
   ],
   "source": [
    "X_train.loc[:, 'stem_lemma_list'] = X_train.loc[:, 'text'].apply(stem_and_lemmatize_and_tokenize)\n",
    "vocab_stemmed_and_lemmatized = set(X_train['stem_lemma_list'].explode())\n",
    "print('Size of raw vocabulary:                   ', len(vocab_raw),\n",
    "      '\\nSize of stemmed vocabulary:               ', len(vocab_stemmed),\n",
    "      '\\nSize of lemmatized vocabulary:            ', len(vocab_lemmatized),\n",
    "      '\\nSize of stemmed and lemmatized vocabulary:', len(vocab_stemmed_and_lemmatized)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f80244cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-91f45a5a7bce>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['text_stemmed_and_lemmatized'] = X_train['stem_lemma_list'].apply(lambda x: stringify(x))\n"
     ]
    }
   ],
   "source": [
    "X_train['text_stemmed_and_lemmatized'] = X_train['stem_lemma_list'].apply(lambda x: stringify(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68a1354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality:                    0.6724 \n",
      "All Words:                    0.7005 \n",
      "Stemmed Words:                0.6995 \n",
      "Lemmatized Words:             0.6986 \n",
      "Stemmed and Lemmatized Words: 0.6998\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text_stemmed_and_lemmatized'])\n",
    "\n",
    "stemmed_and_lemmatized_words_cv = round(cross_val_score(baseline_model, X_train_vectorized, y_train).mean(),4)\n",
    "\n",
    "print('Plurality:                   ', plurality_cv,\n",
    "      '\\nAll Words:                   ', all_words_cv,\n",
    "      '\\nStemmed Words:               ', stemmed_words_cv,\n",
    "      '\\nLemmatized Words:            ', lemmatized_words_cv,\n",
    "      '\\nStemmed and Lemmatized Words:', stemmed_and_lemmatized_words_cv\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a3c06",
   "metadata": {},
   "source": [
    "using all words, whether stemmed and/or lemmatized or not, is hardly different at a glance\n",
    "\n",
    "stemmed and lemmatized has the smallest vocabulary to work with, and if we keep a feature that has the text already stemmed and lemmatized, that will save time when running various models and not having to direct the tokenizer parameter to stem and lemmatize the document all over again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
